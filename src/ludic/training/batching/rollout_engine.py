from __future__ import annotations

import asyncio
import math
import json
import os
from pathlib import Path
from typing import Any, Callable, Dict, List, Mapping, Optional, Sequence, Tuple

from ludic.envs.env import LudicEnv
from ludic.interaction.base import InteractionProtocol
from ludic.types import Rollout, SamplingArgs

from ludic.training.types import (
    CreditAssigner,
    SAWItem,
    SAWBatch,
    TokenizeFn,
    RolloutRequest,
    ProtocolSpec,
    EnvSpec,
)

# ---------------------------------------------------------------------------
# Factory aliases
# ---------------------------------------------------------------------------

EnvFactory = Callable[..., LudicEnv]
ProtocolFactory = Callable[..., InteractionProtocol]

EnvRegistry = Dict[str, EnvFactory]
ProtocolRegistry = Dict[str, ProtocolFactory]

_TOKEN_TRACE_KEYS = {
    "prompt_token_ids",
    "completion_token_ids",
    "completion_logprobs",
}


def _require_finite(value: float, *, what: str, rollout_id: str, step_index: int) -> None:
    if not math.isfinite(value):
        raise ValueError(f"Non-finite {what} for rollout {rollout_id}, step {step_index}: {value!r}")


def _get_credit_weight(
    weights: Mapping[Tuple[str, int], float],
    *,
    rollout_id: str,
    step_index: int,
) -> float:
    key = (rollout_id, step_index)
    try:
        w_raw = weights[key]
    except KeyError as exc:
        raise KeyError(
            "CreditAssigner did not provide a weight for "
            f"(rollout_id={rollout_id!r}, step_index={step_index}). "
            "All steps must be covered."
        ) from exc
    w = float(w_raw)
    _require_finite(w, what="credit weight", rollout_id=rollout_id, step_index=step_index)
    return w


def _extract_model_token_ids(
    info: Mapping[str, Any],
) -> Optional[Tuple[List[int], List[int]]]:
    prompt_ids = info.get("prompt_token_ids")
    completion_ids = info.get("completion_token_ids")
    if (
        isinstance(prompt_ids, list)
        and isinstance(completion_ids, list)
        and all(isinstance(t, int) for t in prompt_ids)
        and all(isinstance(t, int) for t in completion_ids)
    ):
        return prompt_ids, completion_ids
    return None


def _coerce_completion_logprobs(
    completion_logprobs: object,
    *,
    completion_ids: Sequence[int],
    rollout_id: str,
    step_index: int,
) -> Optional[List[float]]:
    if completion_logprobs is None:
        return None
    if not isinstance(completion_logprobs, list) or not all(
        isinstance(v, (int, float)) for v in completion_logprobs
    ):
        raise ValueError(
            f"Invalid completion_logprobs type for rollout {rollout_id}, step {step_index}; "
            "expected List[float]."
        )
    if len(completion_logprobs) != len(completion_ids):
        raise ValueError(
            f"completion_logprobs length mismatch for rollout {rollout_id}, step {step_index} "
            f"({len(completion_logprobs)} vs {len(completion_ids)})."
        )
    return [float(v) for v in completion_logprobs]


def _drop_model_trace_keys(info: Mapping[str, Any]) -> Dict[str, Any]:
    return {k: v for k, v in info.items() if k not in _TOKEN_TRACE_KEYS}


def _base_item_meta(*, rollout: Rollout, step_index: int, reward: float, comp_len: int, prev_obs: str, action: str) -> Dict[str, Any]:
    return {
        "rollout_id": rollout.id,
        "step_index": step_index,
        "reward": reward,
        "prev_obs": prev_obs,
        "action": action,
        "total_reward": rollout.total_reward,
        "completion_length": comp_len,
        **(rollout.meta),  # Rollout-level meta
    }


def _saw_item_from_model_ids(
    *,
    rollout: Rollout,
    step_index: int,
    reward: float,
    weight: float,
    prev_obs: str,
    action: str,
    prompt_ids: Sequence[int],
    completion_ids: Sequence[int],
    step_info: Mapping[str, Any],
    completion_logprobs: Optional[List[float]],
) -> Tuple[SAWItem, int]:
    input_ids = list(prompt_ids) + list(completion_ids)
    attention_mask = [1] * len(input_ids)
    action_mask = [0] * len(prompt_ids) + [1] * len(completion_ids)
    comp_len = len(completion_ids)

    meta = _base_item_meta(
        rollout=rollout,
        step_index=step_index,
        reward=reward,
        comp_len=comp_len,
        prev_obs=prev_obs,
        action=action,
    )
    meta.update(step_info)
    if completion_logprobs is not None:
        meta["completion_logprobs"] = completion_logprobs

    return (
        SAWItem(
            input_ids=input_ids,
            attention_mask=attention_mask,
            action_mask=action_mask,
            weight=weight,
            meta=meta,
        ),
        comp_len,
    )


def _saw_item_from_retokenize(
    *,
    rollout: Rollout,
    step_index: int,
    reward: float,
    weight: float,
    prev_obs: str,
    action: str,
    tokenize: TokenizeFn,
    step_info: Mapping[str, Any],
) -> Tuple[SAWItem, int]:
    state_ids = tokenize(prev_obs)
    action_ids = tokenize(action)
    comp_len = len(action_ids)

    input_ids = state_ids + action_ids
    attention_mask = [1] * len(input_ids)
    action_mask = [0] * len(state_ids) + [1] * len(action_ids)

    meta = _base_item_meta(
        rollout=rollout,
        step_index=step_index,
        reward=reward,
        comp_len=comp_len,
        prev_obs=prev_obs,
        action=action,
    )
    meta.update(_drop_model_trace_keys(step_info))

    return (
        SAWItem(
            input_ids=input_ids,
            attention_mask=attention_mask,
            action_mask=action_mask,
            weight=weight,
            meta=meta,
        ),
        comp_len,
    )


class RolloutEngine:
    """
    Stateless rollout executor.
    
    Responsibilities:
      1. Instantiating Envs and Protocols from Requests.
      2. Executing Episodes (generate_rollouts).
      3. Collating Training Data (generate_batch).
    """

    def __init__(
        self,
        *,
        env_registry: EnvRegistry,
        protocol_registry: ProtocolRegistry,
        jsonl_path: Optional[str] = None,
    ) -> None:
        self.env_registry = dict(env_registry)
        self.protocol_registry = dict(protocol_registry)
        self.jsonl_path = jsonl_path

        if self.jsonl_path:
            Path(os.path.dirname(self.jsonl_path) or ".").mkdir(
                parents=True, exist_ok=True
            )

    # ---- registry helpers ------------------------------------------------
    def _build_env(self, spec: EnvSpec) -> LudicEnv:
        """Instantiate an Env from an EnvSpec via the env_registry."""
        try:
            factory = self.env_registry[spec.kind]
        except KeyError as exc:
            raise KeyError(f"Unknown env kind: {spec.kind!r}") from exc
        return factory(**spec.kwargs)

    def _build_protocol(self, spec: ProtocolSpec) -> InteractionProtocol:
        """Instantiate an InteractionProtocol from a ProtocolSpec via the registry."""
        try:
            factory = self.protocol_registry[spec.kind]
        except KeyError as exc:
            raise KeyError(f"Unknown protocol kind: {spec.kind!r}") from exc
        return factory(**spec.kwargs)

    # ---- internal helpers ------------------------------------------------

    async def _run_one_request(
        self,
        request: RolloutRequest,
        episode_idx: int,
        sem: asyncio.Semaphore,
        *,
        max_steps: int,
        timeout_s: Optional[float],
    ) -> List[Rollout]:
        """
        Run a single rollout for a given RolloutRequest.
        """
        async with sem:
            # 1. Create a fresh, independent protocol worker (and its agent)
            protocol = self._build_protocol(request.protocol)

            # 2. Create a fresh env
            env = self._build_env(request.env)

            sargs: SamplingArgs = request.sampling_args or {}

            # 3. Determine the seed to use for env.reset()
            run_seed = request.seed if request.seed is not None else episode_idx
            is_forced_seed = request.seed is not None

            # 4. Run the episode using the fresh protocol and env
            rollouts = await protocol.run(
                env=env,
                max_steps=max_steps,
                seed=run_seed,
                sampling_args=sargs,
                timeout_s=timeout_s,
            )

            # 5. Log metadata for ALL returned rollouts
            for r in rollouts:
                r.meta.setdefault("episode_idx", episode_idx)
                
                # We flatten the request metadata into the rollout metadata
                # so keys like 'policy_version' are accessible at the top level.
                if request.meta:
                    r.meta.update(request.meta)

                r.meta.setdefault("request_meta", {})
                r.meta["request_meta"].update(request.meta)
                r.meta.setdefault("engine", {})
                r.meta["engine"].update(
                    {
                        "max_steps": max_steps,
                        "timeout_s": timeout_s,
                        "env_kind": request.env.kind,
                        "protocol_kind": request.protocol.kind,
                        "used_seed": run_seed,
                        "forced_seed": is_forced_seed,
                    }
                )

                if self.jsonl_path:
                    self._append_jsonl(r)

            return rollouts

    def _append_jsonl(self, rollout: Rollout) -> None:
        assert self.jsonl_path is not None
        payload = {
            "id": rollout.id,
            "meta": rollout.meta,
            "steps": [
                {
                    "index": s.index,
                    "prev_obs": s.prev_obs,
                    "action": s.action,
                    "next_obs": s.next_obs,
                    "reward": s.reward,
                    "truncated": s.truncated,
                    "terminated": s.terminated,
                    "info": s.info,
                    "ts_ns": s.ts_ns,
                }
                for s in rollout.steps
            ],
            "total_reward": rollout.total_reward,
            "length": rollout.length,
            "duration_ns": rollout.duration_ns,
        }
        with open(self.jsonl_path, "a", encoding="utf-8") as f:
            f.write(json.dumps(payload, ensure_ascii=False) + "\n")

    # ---- rollout generation ----------------------------------------------

    async def generate_rollouts(
        self,
        *,
        requests: List[RolloutRequest],
        max_steps: int,
        timeout_s: Optional[float] = None,
        concurrency: int = 8,
    ) -> List[Rollout]:
        """
        Run all rollouts described by `requests` and return them.
        """
        if not requests:
            return []

        sem = asyncio.Semaphore(max(1, concurrency))
        tasks: List[asyncio.Task[List[Rollout]]] = []

        global_idx = 0
        for req in requests:
            for _ in range(req.num_episodes):
                tasks.append(
                    asyncio.create_task(
                        self._run_one_request(
                            request=req,
                            episode_idx=global_idx,
                            sem=sem,
                            max_steps=max_steps,
                            timeout_s=timeout_s,
                        )
                    )
                )
                global_idx += 1

        results = await asyncio.gather(*tasks)
        # Flatten the list of lists (one list per episode -> single flat list of rollouts)
        return [r for sublist in results for r in sublist]

    # ---- SAW batch generation --------------------------------------------

    async def generate_batch(
        self,
        *,
        requests: List[RolloutRequest],
        max_steps: int,
        credit_assigner: CreditAssigner,
        timeout_s: Optional[float] = None,
        concurrency: int = 8,
        retokenize: bool = False,
        tokenize: Optional[TokenizeFn] = None,
    ) -> SAWBatch:
        """
        High-level entrypoint for RL-style training:
        
        1. Generates rollouts.
        2. Computes credit (advantages/rewards).
        3. Collates into SAWItems (handling tokenization/masking).
        
        Tokenization strategy:
        - If Step.info contains `prompt_token_ids` and `completion_token_ids`,
          those are used *unless* retokenize=True.
        - Otherwise, if retokenize=True, use provided tokenizer.
        - Else raise an error.
        """
        assert (not retokenize) or tokenize, (
            "Either use a chat client that populates token IDs, "
            "or pass a tokenizer if retokenize=True."
        )

        rollouts = await self.generate_rollouts(
            requests=requests,
            max_steps=max_steps,
            timeout_s=timeout_s,
            concurrency=concurrency,
        )
        weights = credit_assigner.compute(rollouts)

        items: List[SAWItem] = []
        completion_lengths: List[int] = []

        for r in rollouts:
            for step in r.steps:
                w = _get_credit_weight(weights, rollout_id=r.id, step_index=step.index)
                reward = float(step.reward)
                _require_finite(reward, what="reward", rollout_id=r.id, step_index=step.index)

                info = step.info or {}
                model_ids = _extract_model_token_ids(info)

                if model_ids is not None and not retokenize:
                    prompt_ids, completion_ids = model_ids
                    completion_logprobs = _coerce_completion_logprobs(
                        info.get("completion_logprobs"),
                        completion_ids=completion_ids,
                        rollout_id=r.id,
                        step_index=step.index,
                    )
                    item, comp_len = _saw_item_from_model_ids(
                        rollout=r,
                        step_index=step.index,
                        reward=reward,
                        weight=w,
                        prev_obs=step.prev_obs,
                        action=step.action,
                        prompt_ids=prompt_ids,
                        completion_ids=completion_ids,
                        step_info=info,
                        completion_logprobs=completion_logprobs,
                    )
                else:
                    if not retokenize:
                        raise ValueError(
                            f"Missing model token IDs for rollout {r.id}, step {step.index}, "
                            "and retokenize=False. Either enable retokenize=True or fix your "
                            "Agent/run_episode to store 'prompt_token_ids' and "
                            "'completion_token_ids' in Step.info."
                        )
                    assert tokenize is not None
                    item, comp_len = _saw_item_from_retokenize(
                        rollout=r,
                        step_index=step.index,
                        reward=reward,
                        weight=w,
                        prev_obs=step.prev_obs,
                        action=step.action,
                        tokenize=tokenize,
                        step_info=info,
                    )

                items.append(item)
                completion_lengths.append(comp_len)

        # ---- Build batch-level metadata -----------------------------------
        # Note: num_rollouts reflects total number of *agent trajectories*, not global env episodes.
        meta = {
            "num_rollouts": len(rollouts),
            "num_samples": len(items),
            "avg_total_reward": (
                float(sum(r.total_reward for r in rollouts) / len(rollouts))
                if rollouts else 0.0
            ),
            "avg_completion_length": (
                float(sum(completion_lengths) / len(completion_lengths))
                if completion_lengths else 0.0
            ),
        }

        return SAWBatch(items=items, meta=meta)
